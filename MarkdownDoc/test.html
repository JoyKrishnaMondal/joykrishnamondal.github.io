
<h1 align = "center">Tacticle Perception with Autonomous Control</h1>
<div align="center">Joy Krishna Mondal </div>
<div align = "center">
	jm12752@my.bristol.ac.uk
</div>
<h2>Introduction</h2>
<p>
Tactile perception would be a key component if fully autonomous robots are to became a reality in the near future. However both  tactile perception and autonomy in robots require significant research and study if we need them to have any major application in our industries and society. <!-- Tactile perception has been left aside for more important study in computer vision for a while in engineering and computational science since it became cheaper to manufacture light sensors than to manufacture expensive touch sensors. This is good news since now we can use the progress made in vision related hardware to improve our understanding of touch -->. To better understand the integration of these two areas of research a spefic problem was choosen from industry that has significant application and that
is of <b>edge</b> and <b>texture</b> detection using a novel new type of tactile sensor.
</p>
<p>
	It is important to emphasis how much progress we can make in the field of robotics by creating better algoritms, sensors, etc in the domain of touch. Physically speaking there is only so much information we can use for inference from the electromagnetic spectrum. Its important to point out that data collected from tactile sensors has helped many organims 'win' the evolutionary game, and almost all form of biologcal intelligence we see incorporates inference from data obtained from touch sensors, it may be that we can successfully create fully autonomuos robots without any form of perception of touch but it would be highly <i>unlikely</i> given the results of billions of years of natural evolution. What this means for this project is that even if the application is very specific it can be generally applied to many more known and unkown problems. For this project we create a closely integrated general system with an industrial arm that would enable the sensor to collect data.
</p>
<p>
	The project in many ways tries to bring two separate worlds together. The progress we have made with general learning algorithms have only been widely applied in mostly IT sectors (search engines, spam filters, data mining , etc), there is significant potential for these classes of algorithms to revolutizie conventional heavy industries such as automotive manufacturing. This project is only a small part of a much larger investigation into these seperate worlds - robotics and machine learning. Philosophically speaking humans are just a big learning algorithm attached to a carbon based robot and it should be worthwhile to study how to create them carbon or not carbon based.

</p>

<h4>Application</h4>

<p>The reason for using a touch sensor in the first place rather than computer vision was because of a very real problem in quality assurance in the automotive manufacturing process.
</p>
Quality assurance in automotive mannufacting generally speaking means assesing the quality of some finished assembly - this assembly could be a car part or a whole car. Currently this is mostly done by manual inspections by engineers or technicians. There are two specific task that they are required to be done:

<ol>
	<li>
		To make sure edge contours of the assembly do not have any defects
	</li>
	<li>
		Notify about any  inconsistencies on the surface finishing.
	</li>
</ol>


To accomplish this the people inspecting would use approximate prior knowledge about the geometry of the assembly. Usually the engineer would use a CAD model to express the geometry of the assembly. There has been attempts made to automate both these problems using computer vision but unfortunately it hasnt been successful.
<p> The reason mainly is due to the fact that light intracts in complex ways with both the material and geometry of a surface, there can be diffraction, surface ray-scattering, subsurface ray-scattering, diffusion, etc . By dectecting the amount of light we recieve after sending a beam can in no way tell us a lot about the surface that is reflecting it, even if we do make some inference it will most likely not be robust and have a lot of uncertainities with it, this problem becames much more naused in materials such as rubber which are genrally very matte and diffuse most of the incoming rays.
</p>
<h4>Project Goals</h4>
To summarize there are two main goals of this project
<ol>
	<li>
		Create a robust algorithm to anaylze sensor data.
	</li>
	<li>
		Create an autonomous control algorithm for the industrial arm that uses the algorithm for edge , contour and texture detection.
	</li>
</ol>

<h2>Methods</h2>
The main domain where we <i>do</i> use a lot of robots is a good place to start our investigation on the current state of the art in robotics. This would be in manufacting, however most of it is automatic and not autonomous and requires an army of skilled proffesionals to program each and every task for a robot.

<h4>Infastructure</h4>
<p>
	One of the key thing that is missing for us to continue our investigation is infastructure, specifically a bridge between our mathematical representation and the physical reality in an assembly line or in a labatory.
</p>
<p>
	Creating this infastrcture is a key part of this report and project. Due to the practical nature of the applicaiton we will be working with and developing on two key pieces of hardware
	<ol>
		<li>An actual pick-and-move industrial arm that is widely used in factory floor.</li>
		<li>A specially designed tactip sensor that uses an webcam to capture images of a LED covered surface that comes in contact with the topology we are investigating. </li>
	</ol>
</p>
<h5>Industrial Arm</h5>
<p>
	The arm we have been given is an ABB IRB-series. It has 6 Degrees of Freedom and specifies it movement using 3D matries and quaternions for orientation and rotation. We will be limiting the application of the arm to 2D but we still need to create our solution with 3D in mind but only in a single plane. Using the arm for our perticular algorithm requires significant study as there are no ready made software solutions to connect our algorithm to the industrial arm. The industrial arm can only understand a programming language created by ABB called RAPID which can be though of as a domain specific language tailored for controlling industrial robots created by them.
	<p>
		ABB has provided us with a Software Development Kit (SDK) to develop software to control the robot. The SDK consists of 2 <code>.dll</code> files which are dynamic link libraries - essentially binaries for the windows platform which we need specific windows tools to develop on.

	</p>
	<p>
		The unfortunate part is the SDK only allows us to send RAPID instructions and not pure data and we need to fully understand specific details about the Common Language Runtime and RAPID.
	</p>
	<p>
		The industrial arm also cannot directly be controlled. We can only send RAPID instructions to a controller that is attached to the industrial arm and then ABB specific sub-routines are called that directly manipulates the industrial arm.
	</p>
</p>

<h4>Tactip Sensor</h4>
The way the Tactip Sensor works is based on the interaction of the topology we are analysing with another surface that has an LED grid placed on it. A webcam provides a live feed of the LED grid. When the topology comes in contact with the surface with the LED grid attached, the webcam feed will show the changes on the grid surface.
This subtle changes in brightness that we observe in the webcam is the source of our data. One of the main tasks of our project is to create a suitable algorithm that transforms this data into a topoloy map which we will use to classify and make decisions.


<h4>Learing Algorithm</h4>

<p>
	Autonomy is a hard concept to define accurately, for the purposes of our project what we mean by autonomy is the lack of programming rules for the analysis of our sensor data. What we want to do is provide the algorithm a set of training data which it should use to create its own rules and use them to analyse the data. It should also use the test data for training and learing to either creat new rules or solidifing its prior knowledge.
</p>







<h2>Results</h2>
<p>

</p>
<h2>Discussion</h2>
<p>

</p>




